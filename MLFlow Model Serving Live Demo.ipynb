{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11636748",
   "metadata": {},
   "source": [
    "## MLFlow Model Serving - MLFlow 2.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e71883",
   "metadata": {},
   "source": [
    "#### Topics Covered:\n",
    "\n",
    "* Conda Environment Creation\n",
    "* Model training important steps written as python function\n",
    "* Train basic classifier and log it as a experiment\n",
    "\n",
    "\n",
    "* Different methods to register ML model in MLFlow Registry\n",
    "* Transition Model stage : None(default), Staging, Production or Archived\n",
    "* Load Model from MLflow Registry and do Prediction\n",
    "* Model Serving - Serving an ML Model from MLFlow Model Registry\n",
    "\n",
    "will see how to log various paramets, model metrics, model itself and other aertifacts like charts etc. \n",
    "\n",
    "**Explanation with live demo is also available at :**\n",
    "\n",
    "* **MLFlow Part 1: Experiment Tracking using MLFlow -  https://www.youtube.com/watch?v=r0do1KVEGqM**\n",
    "\n",
    "* **MLFlow Part 2: Model Serving from MLFlow Model Registry - URL you are watching**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f2e54f",
   "metadata": {},
   "source": [
    "<img src='mlflow.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11e0550",
   "metadata": {},
   "source": [
    "### Create Conda environment\n",
    "\n",
    "1. `conda create -n envname python=3.9 ipykernel` \n",
    "it will create a conda env named envname and install python version 3.9 and a ipykernel inside this environment\n",
    "\n",
    "2. Activate the environment\n",
    "`conda activate envname`\n",
    "\n",
    "3. add newly created environment to the notebook as kernel\n",
    "`python -m ipykernel install --user --name=envname` \n",
    "\n",
    "4. install notebook inside the environment\n",
    "`pip install notebook`\n",
    "\n",
    "5. Now install all required dependencies to run this notebook\n",
    "\n",
    "* `pip install pandas`\n",
    "* `pip install numpy`\n",
    "* `pip install scikit-learn`\n",
    "* `pip install matplotlib`\n",
    "* `pip install mlflow`\n",
    "\n",
    "Now open the notebook using below command: (from the anaconda prompt inside conda environment)\n",
    "\n",
    "`jupyter notebook`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa8fea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlflow --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42394d9",
   "metadata": {},
   "source": [
    "### Create functions for all the steps involved in complete model training lifecycle\n",
    "Note: Model creation is not the main purpose of this notebook so not everything related to data cleaning and preprocissing is present. Main idea is to understand how to track experiment using MLFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8185d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(url):\n",
    "    import pandas as pd\n",
    "    # Load dataset\n",
    "    data = pd.read_csv(filepath_or_buffer=url,sep=',')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75479a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(final_data,target_column):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X = final_data.loc[:, final_data.columns != target_column]\n",
    "    y = final_data.loc[:, final_data.columns == target_column]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,stratify = y, random_state=47)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5825d668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_basic_classifier(X_train,y_train):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    classifier = LogisticRegression()\n",
    "    classifier.fit(X_train,y_train)\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c34747b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_test_data(model,X_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2087986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_prob_on_test_data(model,X_test):\n",
    "    y_pred = model.predict_proba(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ac32a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_true, y_pred, y_pred_prob):\n",
    "    from sklearn.metrics import accuracy_score,precision_score,recall_score,log_loss\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred,average='micro')\n",
    "    recall = recall_score(y_true, y_pred,average='micro')\n",
    "    entropy = log_loss(y_true, y_pred_prob)\n",
    "    return {'accuracy': round(acc, 2), 'precision': round(prec, 2), 'recall': round(recall, 2), 'entropy': round(entropy, 2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f767837c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_roc_auc_plot(clf, X_data, y_data):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn import metrics\n",
    "    metrics.plot_roc_curve(clf, X_data, y_data) \n",
    "    plt.savefig('roc_auc_curve.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83ae255b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_confusion_matrix_plot(clf, X_test, y_test):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import plot_confusion_matrix\n",
    "    plot_confusion_matrix(clf, X_test, y_test)\n",
    "    plt.savefig('confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b696d16",
   "metadata": {},
   "source": [
    "### Start calling above functions one by one and see the output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf35cdd5",
   "metadata": {},
   "source": [
    "**Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c828739b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal-length</th>\n",
       "      <th>sepal-width</th>\n",
       "      <th>petal-length</th>\n",
       "      <th>petal-width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal-length  sepal-width  petal-length  petal-width        class\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/TripathiAshutosh/dataset/main/iris.csv'\n",
    "data = load_data(url)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8c56ed",
   "metadata": {},
   "source": [
    "**Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31cc680a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'class'\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "875b89a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal-length</th>\n",
       "      <th>sepal-width</th>\n",
       "      <th>petal-length</th>\n",
       "      <th>petal-width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal-length  sepal-width  petal-length  petal-width\n",
       "26            5.0          3.4           1.6          0.4\n",
       "41            4.5          2.3           1.3          0.3\n",
       "49            5.0          3.3           1.4          0.2\n",
       "44            5.1          3.8           1.9          0.4\n",
       "141           6.9          3.1           5.1          2.3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d214353",
   "metadata": {},
   "source": [
    "**Model Training** (Basic classifier, as here idea is not to create the best model however focus is on MLFlow model serving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "503cd606",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mustapha.BOUYAALA\\Logiciels\\anaconda3\\envs\\dev310\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Mustapha.BOUYAALA\\Logiciels\\anaconda3\\envs\\dev310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model = training_basic_classifier(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8ddc26",
   "metadata": {},
   "source": [
    "**See the prediction outcome**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b650dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = predict_on_test_data(model,X_test)\n",
    "print(y_pred)\n",
    "y_pred_prob = predict_prob_on_test_data(model,X_test)\n",
    "print(y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac3d8ab",
   "metadata": {},
   "source": [
    "**print some metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c013fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_metrics = get_metrics(y_test, y_pred, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472e4c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034ad9f6",
   "metadata": {},
   "source": [
    "**Generate Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ca5866",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_confusion_matrix_plot(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d82507c",
   "metadata": {},
   "source": [
    "### Define create_experiment function to track your model experiment within MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2776f31e",
   "metadata": {},
   "source": [
    "# Modéle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff279067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# model est votre modèle de machine learning\n",
    "model_pkl = pickle.dumps(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de18770a",
   "metadata": {},
   "source": [
    "# MYSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1030e83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import mlflow\n",
    "\n",
    "db_model = 'model_dain'\n",
    "db_model_table = 'MLmodel'\n",
    "\n",
    "mysql_conn_str = f\"mysql+pymysql://root:dain@localhost:3306/{db_model}\"\n",
    "create_table = f\"CREATE TABLE IF NOT EXISTS {db_model_table} (id INT AUTO_INCREMENT PRIMARY KEY, model_data BLOB);\"\n",
    "\n",
    "# Configuration de la connexion à MySQL\n",
    "engine = create_engine(mysql_conn_str)\n",
    "\n",
    "# Configuration de MLflow pour utiliser la base de données MySQL\n",
    "mlflow.set_tracking_uri(mysql_conn_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f33dcde",
   "metadata": {},
   "source": [
    "# Create data base if not exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1575f09e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pymysql\n",
    "def creation_db(db_model = ['model_dain', 'dain']):\n",
    "    for db in db_model:\n",
    "        create_db = f\"CREATE DATABASE IF NOT EXISTS {db}\"\n",
    "        conn_db = pymysql.connect(host='localhost', user='root', password='dain')\n",
    "        cursor = conn_db.cursor()\n",
    "        cursor.execute(create_db)\n",
    "        cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd10bc0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create data base\n",
    "creation_db()\n",
    "# creation table\n",
    "engine.execute(create_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6375dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérer le modèle dans la table\n",
    "engine.execute(f\"INSERT INTO {db_model_table} (model_data) VALUES (%s)\", (model_pkl,))\n",
    "engine.execute('commit')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c4f449",
   "metadata": {},
   "source": [
    "# Load model from mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a2d4d57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Récupérer le modèle depuis la table\n",
    "model_data= engine.execute(\"SELECT model_data FROM MLmodel WHERE id = %s\", (1,)).fetchone()[0]\n",
    "# Désérialiser le modèle\n",
    "loaded_model = pickle.loads(model_data)\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d26e9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mustapha.BOUYAALA\\Logiciels\\anaconda3\\envs\\dev310\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Mustapha.BOUYAALA\\Logiciels\\anaconda3\\envs\\dev310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model_1 = loaded_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44ee6235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle chargé : 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "pred = model_1.predict(X_test)\n",
    "\n",
    "# Évaluer les performances du modèle chargé\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "print(f\"Précision du modèle chargé : {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d71530",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be77e78",
   "metadata": {},
   "source": [
    "# Autre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7c7f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "mysql_conn_str = f\"mysql+pymysql://root:dain@localhost:3306/dain\"\n",
    "db_connection = create_engine(mysql_conn_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f338521f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "query=\"SELECT * FROM metrics where metrics.date between '2021-06-15' and  '2023-03-29' \"\n",
    "df_q = pd.read_sql(query, con=db_connection)\n",
    "df_q.index=df_q['date']\n",
    "df_q = df_q.drop(['date'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29363e78",
   "metadata": {},
   "source": [
    "# optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9b3dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    x = trial.suggest_uniform('x', -10, 10)\n",
    "    return (x - 2) ** 2  # Fonction à minimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6751d7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad6fd61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823648ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "print('Value: ', trial.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff91df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Params: ')\n",
    "for key, value in trial.params.items():\n",
    "    print(f'    {key}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cec9380",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf5d174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_experiment(experiment_name,run_name, run_metrics,model, confusion_matrix_path = None, \n",
    "                      roc_auc_plot_path = None, run_params=None):\n",
    "    import mlflow\n",
    "    #mlflow.set_tracking_uri(\"http://localhost:5000\") \n",
    "    #use above line if you want to use any database like sqlite as backend storage for model else comment this line\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        \n",
    "        if not run_params == None:\n",
    "            for param in run_params:\n",
    "                mlflow.log_param(param, run_params[param])\n",
    "            \n",
    "        for metric in run_metrics:\n",
    "            mlflow.log_metric(metric, run_metrics[metric])\n",
    "        \n",
    "        \n",
    "        \n",
    "        if not confusion_matrix_path == None:\n",
    "            mlflow.log_artifact(confusion_matrix_path, 'confusion_materix')\n",
    "            \n",
    "        if not roc_auc_plot_path == None:\n",
    "            mlflow.log_artifact(roc_auc_plot_path, \"roc_auc_plot\")\n",
    "        \n",
    "        mlflow.set_tag(\"tag1\", \"Iris Classifier\")\n",
    "        mlflow.set_tags({\"tag2\":\"Logistic Regression\", \"tag3\":\"Multiclassification using Ovr - One vs rest class\"})\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "    print('Run - %s is logged to Experiment - %s' %(run_name, experiment_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2655b4b7",
   "metadata": {},
   "source": [
    "### Start Mlflow server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfc4eac",
   "metadata": {},
   "source": [
    "**Prefer to run it from command line**\n",
    "\n",
    "`mlflow ui` This will launch mlflow UI in the browser and you can access it using `localhost:5000` but this uses file as backend to store experiments and model artifacts. It does not support model registry functionality. \n",
    "\n",
    "To use model registry, you need to have some backend database other than the file system. Ex mysql, sqlite or any other DB mentioned in mlflow docs under backend storage. Refer: https://www.mlflow.org/docs/latest/tracking.html?highlight=scenario#how-runs-and-artifacts-are-recorded\n",
    "\n",
    "#### In this tutorial , we will use sqlite as backend, so Now run this command to start mlflow with backend.\n",
    "`mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./artifacts --host 0.0.0.0 --port 5000`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d1f5ec",
   "metadata": {},
   "source": [
    "**Execute the create_experiment function and log experiment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ed320e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "experiment_name = \"iris_classifier_\"+ str(datetime.now().strftime(\"%d-%m-%y\")) ##basic classifier\n",
    "run_name=\"iris_classifier_\"+str(datetime.now().strftime(\"%d-%m-%y\"))\n",
    "create_experiment(experiment_name,run_name,run_metrics,model,'confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35482d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "logged_model = 'runs:/2ebd5ce44da047f18799f920ab0b99bb/model'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "# Predict on a Pandas DataFrame.\n",
    "import pandas as pd\n",
    "loaded_model.predict(pd.DataFrame(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdd29ef",
   "metadata": {},
   "source": [
    "**Open http://localhost:5000 in the browser, here you will find the recorded experiment**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81bd8e1",
   "metadata": {},
   "source": [
    "### Adding an MLflow Model to the Model Registry\n",
    "Reference: https://www.mlflow.org/docs/latest/model-registry.html\n",
    "\n",
    "There are three programmatic ways to add a model to the registry. \n",
    "First, you can use the mlflow.<model_flavor>.log_model() method. \n",
    "For example, in your code:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a42d321",
   "metadata": {},
   "source": [
    "#### Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bb75a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_exp_and_register_model(experiment_name,run_name,run_metrics,model,confusion_matrix_path = None, \n",
    "                      roc_auc_plot_path = None, run_params=None):\n",
    "    mlflow.set_tracking_uri(\"http://localhost:5000\") \n",
    "    #use above line if you want to use any database like sqlite as backend storage for model else comment this line\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    with mlflow.start_run(run_name=run_name) as run:\n",
    "        if not run_params == None:\n",
    "            for param in run_params:\n",
    "                mlflow.log_param(param, run_params[param])\n",
    "            \n",
    "        for metric in run_metrics:\n",
    "            mlflow.log_metric(metric, run_metrics[metric])\n",
    "        \n",
    "        if not confusion_matrix_path == None:\n",
    "            mlflow.log_artifact(confusion_matrix_path, 'confusion_materix')\n",
    "            \n",
    "        if not roc_auc_plot_path == None:\n",
    "            mlflow.log_artifact(roc_auc_plot_path, \"roc_auc_plot\")\n",
    "        \n",
    "        mlflow.set_tag(\"tag1\", \"Random Forest\")\n",
    "        mlflow.set_tags({\"tag2\":\"Randomized Search CV\", \"tag3\":\"Production\"})\n",
    "        mlflow.sklearn.log_model(model, \"model\",registered_model_name=\"iris-classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618f1afa",
   "metadata": {},
   "source": [
    "In the above code snippet, if a registered model with the name doesn’t exist, the method registers a new model and creates Version 1. If a registered model with the name exists, the method creates a new model version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ad6273",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"iris_classifier_method-1\" #+ str(datetime.now().strftime(\"%d-%m-%y\")) ##basic classifier\n",
    "run_name=\"iris_classifier_method-5\" #+str(datetime.now().strftime(\"%d-%m-%y\"))\n",
    "create_exp_and_register_model(experiment_name,run_name,run_metrics,model,'confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c529fd0",
   "metadata": {},
   "source": [
    "#### Method 2\n",
    "The second way is to use the mlflow.register_model() method, after all your experiment runs complete and when you have decided which model is most suitable to add to the registry. For this method, you will need the run_id as part of the runs:URI argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0ebaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    result = mlflow.register_model(\n",
    "        \"runs:/0ba6d1ccf6df430d9982308360533f02/model\",\n",
    "        \"iris-classifier-8\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4e2391",
   "metadata": {},
   "source": [
    "If a registered model with the name doesn’t exist, the method registers a new model, creates Version 1, and returns a ModelVersion MLflow object. If a registered model with the name exists, the method creates a new model version and returns the version object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c2c8cb",
   "metadata": {},
   "source": [
    "#### Method 3\n",
    "And finally, you can use the create_registered_model() to create a new registered model. If the model name exists, this method will throw an MlflowException because creating a new registered model requires a unique name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c47093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "client.create_registered_model(\"basic-classifier-method-3\")\n",
    "\n",
    "#While the method above creates an empty registered model with no version associated, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f8f979",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the method below creates a new version of the model.\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "result = client.create_model_version(\n",
    "    name=\"basic-classifier-method-1\",\n",
    "    source=\"dff923c9e0924e8e968eaed4cab33ee9/artifacts/model\",\n",
    "    ruan_id=\"dff923c9e0924e8e968eaed4cab33ee9\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3907f50f",
   "metadata": {},
   "source": [
    "### Fetching an MLflow Model from the Model Registry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0869a7d",
   "metadata": {},
   "source": [
    "**Fetch a specific model version**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9032612",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import mlflow.pyfunc\n",
    "\n",
    "model_name = \"iris-classifier\"\n",
    "model_version = 1\n",
    "\n",
    "model = mlflow.pyfunc.load_model(\n",
    "    model_uri=f\"models:/{model_name}/{model_version}\"\n",
    ")\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "sklearn_model = mlflow.sklearn.load_model(\n",
    "    model_uri=f\"models:/{model_name}/{model_version}\"\n",
    ")\n",
    "y_pred_prob = sklearn_model.predict_proba(X_test)\n",
    "print(y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d498465d",
   "metadata": {},
   "source": [
    "**Fetch the latest model version in a specific stage**\n",
    "\n",
    "To fetch a model version by stage, simply provide the model stage as part of the model URI, and it will fetch the most recent version of the model in that stage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66a1fbf",
   "metadata": {},
   "source": [
    "#### Transitioning an MLflow Model’s Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d41ae0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "client = mlflow.tracking.MlflowClient()\n",
    "client.transition_model_version_stage(\n",
    "    name=\"iris-classifier\",\n",
    "    version=1,\n",
    "    stage=\"Production\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf497b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.pyfunc\n",
    "\n",
    "model_name = \"iris-classifier\"\n",
    "stage = 'Production'\n",
    "\n",
    "model = mlflow.pyfunc.load_model(\n",
    "    model_uri=f\"models:/{model_name}/{stage}\"\n",
    ")\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4d1f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.pyfunc\n",
    "\n",
    "model_name = \"iris-classifier\"\n",
    "stage = 'Production'\n",
    "\n",
    "model = mlflow.sklearn.load_model(\n",
    "    model_uri=f\"models:/{model_name}/{stage}\"\n",
    ")\n",
    "\n",
    "y_pred = model.predict([[6.7,3.3,5.7,2.1]])\n",
    "print(y_pred)\n",
    "y_pred_prob = model.predict_proba([[6.7,3.3,5.7,2.1]])\n",
    "print(y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b462895",
   "metadata": {},
   "source": [
    "### Serving an MLflow Model from Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eb4ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri('http://localhost:5000')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26a7809",
   "metadata": {},
   "source": [
    "**Run this from command line**\n",
    "`set MLFLOW_TRACKING_URI=http://localhost:5000` #use export MLFLOW_TRACKING_URI=http://localhost:5000 if in linux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e7f1a2",
   "metadata": {},
   "source": [
    "<img src='env variable.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8034a2ff",
   "metadata": {},
   "source": [
    "## **Now run this command from command line**\n",
    "\n",
    "make sure to write the different port - other than the one you used while starting mlflow server\n",
    "\n",
    "`mlflow models serve --model-uri models:/iris-classifier/Production -p 1234 --no-conda`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3d00cb",
   "metadata": {},
   "source": [
    "### Do Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a745b565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "inference_request = {\n",
    "        \"dataframe_records\": [[6.7,3.3,5.7,2.1]]\n",
    "}\n",
    "\n",
    "endpoint = \"http://localhost:1234/invocations\"\n",
    "\n",
    "response = requests.post(endpoint, json=inference_request)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9561d908",
   "metadata": {},
   "source": [
    "### Batch Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e447c4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7002b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "lst = X_test.values.tolist()\n",
    "inference_request = {\n",
    "        \"dataframe_records\": lst\n",
    "}\n",
    "endpoint = \"http://localhost:1234/invocations\"\n",
    "response = requests.post(endpoint, json=inference_request)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a925371",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f115d4f2",
   "metadata": {},
   "source": [
    "## Thank You\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Deploy Model using Python Flask and expose end points\n",
    "2. Deploy Model using FastAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283145c5",
   "metadata": {},
   "source": [
    "# GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5e3a021",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'GPT3LMHeadModel' from 'transformers' (C:\\Users\\Mustapha.BOUYAALA\\Logiciels\\anaconda3\\envs\\dev310\\lib\\site-packages\\transformers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline, GPT3LMHeadModel, GPT3Tokenizer\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Charger le modèle et le tokenizer DistilGPT\u001b[39;00m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m GPT3LMHeadModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistilgpt2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'GPT3LMHeadModel' from 'transformers' (C:\\Users\\Mustapha.BOUYAALA\\Logiciels\\anaconda3\\envs\\dev310\\lib\\site-packages\\transformers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Charger le modèle et le tokenizer DistilGPT\n",
    "model = GPT2LMHeadModel.from_pretrained(\"distilgpt2\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"distilgpt2\")\n",
    "\n",
    "# Générer du texte avec le modèle\n",
    "text_generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "output_text = text_generator(\"Votre texte d'entrée ici.\", max_length=50, num_return_sequences=1)[0]['generated_text']\n",
    "\n",
    "print(output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f2143ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"data scientist. I am the owner of a new lab that has been working on building a new space station, the space station's scientific module. I love experimenting with new technologies and making new discoveries, and I want some creative ideas. I want to\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_generator(\"data scientist.\", max_length=50, num_return_sequences=1)[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f9beb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71e16753",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9994811415672302}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Allocate a pipeline for sentiment-analysis\n",
    "classifier = pipeline('sentiment-analysis')\n",
    "classifier('i have some diffuclte with this programm so i can''t do it.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f04d38",
   "metadata": {},
   "source": [
    "# autre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224a629f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d497467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3c373f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571b706a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6267bac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dd29fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
